# 11장 데이터베이스 기술의 현재와 미래  

## 11.1 데이터베이스 기술 동향  

### 데이터 모델링 및 SQL  

어떤 데이터 항목을 취급할지 정하고 테이블 관계에 반영하는 것을 **데이터 모델링**이라고 한다. RDBMS에서는 데이터 모델링의 성과로 `CREATE TABLE` 문이 나온다. 하지만 테이블 생성 이후에도 스펙 변경 요구가 계속 생길 수 있다. 주로 새로운 열을 추가하거나 열의 정의를 바꾸는 요구 사항이 자주 발생한다. 그래서 다음 두 가지 형태로 제품들이 진화하기 시작했다.  

- 클라이언트 측의 처리가 정지되는 일이 없이 서비스 도중에 정의를 바꿀 수 있다.
- 테이블 정의조차 하지 않고도 일정 이상의 품질로 동작하도록 한다.

### 온라인에서의 정의 변경  

관계형 데이터베이스에서 온라인으로 테이블 정의를 변경하는 경우 부담이 있다. 왜냐하면 정의 변경 동안 전체 테이블에 락을 걸고 업데이트를 하지 못하게 막기 때문이다. 테이블 크기가 클수록 정의 변경에 걸려 갱신을 할 수 없는 시간도 길어진다.  
원래는 테이블 정의 변경을 참조와 갱신을 블록하지 않고도 실행할 수 있어야 한다. 이미 그런 기능을 지원하는 DBMS가 많이 있다. 기본 키를 변경하려는 경우엔 제한되는 부분이 많지만, 보통 기본 키를 변경하려는 경우는 드물기 때문에 문제가 되지 않는다. MySQL에서 온라인 상태에서의 정의 변경을 위한 몇 가지 기술을 소개한다.  

#### 트리거를 사용하여 변경 내용을 기록하고 나중에 한꺼번에 반영  

테이블 정의 변경 중에 갱신된 정보를 트래킹하기 위한 전용 테이블(트래킹 테이블)을 제공한다. 그리고 현재 테이블의 내용을 덤프하고 그것을 새 테이블로 옮긴다. 그러면 새로운 테이블과 현재 테이블 간 데이터 차이가 발생하는데 트래킹 테이블 내용을 새 테이블에 적용해서 싱크를 맞춘다. 싱크를 맞추기 전에 새 기존 테이블에 락을 걸어서 갱신을 멈추고, 싱크를 맞춘 뒤에 새 테이블의 이름을 기존 테이블과 같이 변경한 다음 락을 해제한다. 대부분의 내용을 새 테이블로 옮겨서 트래킹 테이블에 있는 내용만 싱크를 맞추는 경우, 갱신 차단 시간은 아주 짧다.  
위 시나리오대로 적용하려면 `잠금을 걸지 않고 SELECT 한다` 와 `시작 시점에서 커밋된 데이터를 읽는다(읽는 동안 테이블의 갱신되어도 시작 시점에서 커밋된 데이터를 읽어들인다)` 는 기능이 중요하다. 이 기능들 모두 트랜잭션을 기반으로 innoDB에서 지원한다.  

#### 복제 구성 활용  

복제 구성을 하면 더 유연하게 작업할 수 있다. 예를 들어 마스터 한 대, 슬레이브 두 대 구성이라면 **슬레이브에서 먼저 정의 변경을 한다.** 정의 변경을 하는 동안 갱신이 멈추기 때문에 select는 나머지 정의 변경하지 않은 슬레이브를 참조하게 한다. 그래서 교차로 모든 슬레이브에서 정의 변경이 끝나면, 슬레이브 한대를 마스터로 바꾸고, 기존에 마스터였다가 슬레이브가 된 장비도 정의 변경을 한다. 마스터 -> 슬레이브로 전환하기 전에 싱크를 맞추겠지?  

아래 그림은 트래킹 테이블을 이용한 온라인 스키마 변경 과정을 나타낸 것이다.  

![online-schema-change](online-schema-change.jpg)  

트랜잭션 및 복제 기술이 온라인 정의 변경이라는 작업에도 영향을 주고 있고, 이런 기술을 제공하는 것이 DB의 경쟁력이 될 것이다. (이미 되었다.)  

### 스키마 없는 데이터베이스  

데이터 정의 변경에 고통받다가 '아예 정의를 없애보자!' 라면서 나온 개념이다. MySQL 에서 이 개념을 실행하려면 기본 키 또는 일부 인덱스와 같은 대표적인 데이터 항목을 밝혀낸 후 나머지를 `misc TEXT` 등의 형태로 큰 문자열로 정의하는 방법이 있다.  
이 중에는 JSON이나 XML 형태로 존재할 수도 있다. 이런 반정형 형태를 띄고 있다면, 데이터 변경 시 애플리케이션에서 처리가 가능하다. 물론 이런 개념을 차용하고 있는 NoSQL이 있는데 RDBMS에서 하는 것이 조금 이상해보이긴 한다.  

## 11.2 대량의 데이터를 고속으로 처리하는 기술  

데이터 양이 늘어날수록 업데이트 성능과 데이터 탐색 성능은 저하된다. 대량의 데이터에도 성능을 유지하는 것이 중요한데, 이를 위해 다양한 방법을 취하고 있다.  

### 인덱스 성능의 저하 요인  

참조/갱신 성능에 가장 중요한 요소는 **인덱스**이다. 인덱스를 사용하면 빠른 이유는 테이블 전체를 읽지 않아도 되기 때문이다. 하지만 다양한 검색 조건을 위해서 다수의 인덱스를 구성하게 된다면 그에 반해 업데이트 속도는 느려지게 된다. 그래서 요구 사항에 따라서 인덱스를 적절하게 설정하는 것이 중요하다.  
인덱스의 주로 B+Tree로 구현하게 되는데, 참조 및 갱신 모두 `O(logmN)` 으로 처리할 수 있으며, 탐색이 빠른 것이 특징이다. 하지만 B+Tree는 모든 액세스를 랜덤 엑세스로 처리하게 된다. 액세스 되는 블록이 위치 상 군데군데 떨어져서 위치하기 때문에 랜덤 액세스를 거쳐야하는데 HDD의 경우 랜덤 액세스가 매우 느리다.  
또한 인덱스가 메모리에 있는 상태라면 참조/갱신 성능 모두 빠르지만, 크기의 문제로 메모리에 올라가지 못한 경우라면 HDD에서 랜덤 액세스를 해야하기 때문에, 메모리에 있을때에 비해 성능이 크게 떨어지게 된다.  
인덱스 검색/갱신 성능을 저하하는 트리거는 메모리에 인덱스가 들어가지 못할 정도로 데이터 양이 증가한 경우이다. 그래서 인덱스 크기를 줄이는 것이 중요하다. 이후에는 아래와 같은 다양한 방법으로 대량의 데이터를 다루는 방법을 설명한다.  

- 레인지 파티셔닝
- B+Tree 이외의 인덱스
- 고속의 하드웨어
- 트랜잭션

### 레인지 파티셔닝  

인덱스 성능이 떨어지는 가장 큰 요인은 인덱스 사이즈에 있다. MySQL 등 많은 RDBMS가 제공하는 인덱스 사이즈를 줄이는 방법 중 하나가 **레인지 파티셔닝**이다. 이 기능은 테이블 및 인덱스를 물리적으로 한 개로 정리해서 관리하는 것이 아니라 복수로 분할하여 관리하는 방식이다. 특정 파티션에만 액세스를 집중시킬 수 있으면 전체 인덱스 크기보다도 답도적으로 액세스 범위가 좁아지므로 그 파티션은 메모리에 올릴 수 있어서 액세스 성능을 향상시킬 수 있다.  
특정 파티션에만 액세스를 집중시키는 이유는 대부분의 경우, 거대한 데이터는 시간적인 국소성이 매우 높다는 특징이 있다. SNS로 예를 들자면 최근의 글이 1년 전의 글보다 참조 빈도가 훨씬 높을 것이다. 그래서 1주일, 1개월 단위로 파티션을 자르면 인덱스의 크기는 해당 기간에 한정해서 줄어들게 된다. 그러면 해당 파티션에 액세스가 집중하기 때문에 그 파티션에 속하는 인덱스의 내용은 확실하게 캐시가 된다.  

### B+Tree 이외의 인덱스  

메모리에 들어가지 못할 정도로 인덱스의 크기가 비대한 경우에 업데이트 성능이 저하되는 문제는 B+Tree의 구조적인 문제로부터 발생한다. 그래서 인덱스 크기가 커져도 update 성능을 일정 이상 보장하는 새로운 인덱스 구조에 대한 연구가 많이 진행되었다. TokuDB 라는 스토리지 엔진의 Fractal Tree 라는 인덱스에서는 보조 인덱스의 크기가 아무리 커져도 INSERT의 성능을 일정한 라인으로 보장한다고 한다.  

### 고속의 SSD 사용  

SSD는 랜덤 액세스가 빠르기 때문에 (HDD에 비해) 랜덤 액세스 성능 이슈를 많이 줄여주었다.  

### 트랜잭션  

데이터가 날아가서 복구를 해야하는 상황이 생길 때, 원만한 복구를 위해 트랜잭션이 사용된다.(근데 이 내용은 좀 뜬금..)  

#### 정합성이 있는 복제 실현  

복제 구성을 해놓으면 데이터베이스가 다운되더라도 복구가 가능하다. 하지만 데이터의 일관성있는 복구를 위해서는 트랜잭션이 필요하다. 슬레이브가 다운되면 어디까지 업데이트를 완료하고, 어디서부터 다시 복제를 시작하면 될 지 정보를 필요로 한다. 그런데 트랜잭션을 지원하지 않으면 정합성을 보장할 수 없다. 그러면 데이터를 처음부터 전부 복사해와야 하고, 저장한 데이터가 크면 클 수록 오버헤드는 커진다.  

#### 일관성이 있는 백업 보장  

일관성 있는 백업을 하려면 트랜잭션이 필요하다. 복제가 있더라도, 잘못된 업데이트를 하게 되면 마스터를 거쳐 슬레이브까지 잘못된 변경이 싱크되기 때문에 백업은 필요하다. 만약 트랜잭션을 지원하지 않는 제품이라면 서버 업데이트를 중지하는 것 외에는 일관성 있는 백업을 할 수 없다. 그래서 책에서는 트랜잭션을 지원하지 않는 NoSQL 같은 경우엔 프로세스 다운 등으로 데이터를 소실하는 경우가 많다고 한다. (과연...?)  

## 11.3 분석계 처리 및 열 지향 데이터베이스  

### 분석계 처리는 무엇이 어려운가?  

데이터를 저장하는 것도 중요하지만, 저장한 데이터를 활용하는 것 또한 중요하다. 기존 RDBMS는 데이터 웨어하우스와 같은 작업 형태에 최적화되어 있지 않다. 그래서 데이터 분석 자체에 시간이 너무 걸려 현실적인 시간 내에 처리를 완료할 수 없는 일이 발생한다.  

#### DWH형의 테이블  

DWH가 성능 문제를 일으키기 쉬운 이유는 데이터와 레코드 양이 많아지는 것이다. 그림을 보면 테이블의 레코드 수는 테이블 몇 바로 아래에 있는 `SF X 숫자` 다. SF(스케일 팩터)는 벤치마크 시에 이 값을 변화시킴으로써 데이터 크기를 조절할 수 있다.  
그림을 보면 상품 구매 정보가 기록되는 테이블은 시간순으로 주문마다 데이터가 쌓여가는데, 나머지 테이블은 업데이트가 자주 발생하지 않는 마스터 역할을 수행하고 있다. 그래서 row 데이터가 많이 축적되서 레코드 수가 많은 테이블을 `팩트 테이블`, 마스터 역할을 하는 테이블을 `디멘션 테이블` 이라고 한다.  

많은 DWH에서 팩트 테이블 레코드 수는 억 단위를 넘어가기 때문에, 테이블 크기를 최대한 작게 하기 위해서 각 열의 데이터 형식은 효율적인 것이 사용된다. (inverted index) 그리고 중복된 문자열을 모두 남긴다면 너무 공간 낭비가 심하기 때문에 중복 문자열을 처리하는 방법도 가지고 있다. 또한 팩트 테이블에는 다양한 id(column)이 존재하기 때문에 이와 대응되는 디멘션 테이블이 여러 개 있다. 그래서 여러 디멘션 테이블의 데이터를 참조하는 쿼리의 경우 팩트 테이블과 조인이 불가피 할 수도 있다.  

#### DWH형의 SQL 문장  

팩트 테이블과 디멘션 테이블 간의 조인이 많이 발생하고, aggregation 함수도 많이 사용된다. 일반적인 애플리케이션에서 실행하는 SQL 문과는 다른 양상을 보인다.  

#### 레코드와 데이터 사이즈가 크다  

팩트 테이블의 레코드 수가 방대해지면 그에 따라 당연하게 데이터 사이즈도 커진다. 큰 데이터를 처리하려면 디스크 I/O가 많이 발생하고 성능이 저하된다. 그래서 DWH 뿐 아니라 데이터베이스 전반에서 데이터를 작게 만드는 것은 성능에 있어서 중요하다. 얼마나 많은 데이터를 캐시에 두어, 저속의 디스크I/O 비율을 최대한 낮추는 것이 성능에 가장 중요한 것이다.  
팩트 테이블의 데이터 형식으로 문자열보다 공간 효율성이 좋은 숫자가 사용되는 것은 주로 사이즈를 줄이기 위함이다. 그리고 일정 기간이 만료된 데이터는 제거하거나 수평 분할하는 정책을 취하기도 한다.  

### 기존 RDBMS에 있어서의 과제  

#### 처리 대상이 아닌 열에도 액세스가 시행된다  

DWH의 SQL 문 특성 상 소수의 컬럼만 필요한 경우가 많다. 하지만 기존 RDBMS에서는 일부의 컬럼만 필요하더라도 전체 행을 다 읽어야한다. 기존 DB의 처리 단위는 레코드이다. 한 레코드 내의 컬럼 데이터는 물리적으로 인접하여 있다. 그 중 한 컬럼만 필요하더라도 I/O 단위는 블록 단위이기 때문에 나머지 열도 강제로 I/O가 되어버린다. 그러면 컬럼이 많을수록 필요한 컬럼 수와 관계 없이 읽어들여야 하는 컬럼 수는 증가하게 되고 이는 비효율이다. 웹 어플리케이션처럼 한 레코드만 필요한 경우엔 한 블록을 읽는건 당연한 것이고 낭비가 아니다. 하지만 DWH는 수백만 레코드를 읽는 경우가 많기 때문에 이 비효율의 영향이 더 클 수 밖에 없다.  

#### 인덱스 설계가 매우 어렵다  

인덱스를 올바르게 설계하는 것은 어려운데, 무엇을 조건으로 검색할지 처음부터 명확하게 하는 것이 어렵기 때문이다. 검색 시에도 검색 조건에 인덱스가 포함되지 않거나, 순서에 따라 (멀티 컬럼 인덱스) 인덱스를 사용하지 않게 된다. 특히, 분석계 쿼리는 어떠한 관점으로 데이터를 분석할지 처음부터 정해진 것이 아니기 때문에 검색 요구 사항은 항상 바뀔 수 있다. 그래서 인덱스 설정이 쉽지 않다.  

#### 범위 검색으로 대량의 레코드에 매치하기  

인덱스를 사용한다 하더라도 속도가 반드시 개선되는 것은 아니다. 인덱스 검색은 리프 블록을 읽어 일치하는 열 값의 행 번호를 취득한 다음, 일치하는 행 번호 각각에 대해 실제 레코드를 읽는 두 단계로 처리된다. 리프 블록과 나머지 열 값으로의 액세스는 랜덤 엑세스가 된다. 분석계 쿼리에서는 검색에 인덱스가 사용되었다 하더라도, 일치하는 레코드가 너무 많아서 대량의 랜덤 액세스가 발생하는 경우가 많다. 어떤 관점에서 데이터를 찾냐에 따라서, 검색 대상 데이터가 인접해있는 경우에는 시퀀셜 read가 가능하지만, 그렇지 않은 경우에는 랜덤 read가 발생하게 된다.  
인덱스 검색은 기본 키 검색과 같이 극히 제한된 수의 레코드만 일치하는 경우에는 신속하게 이루어지지만, 대량의 레코드가 매치하면 HDD의 랜덤 read 속도로 인해 테이블 풀 스캔보다 속도가 더 느린 경우도 생긴다.  

### 열 지향 데이터베이스란 무엇인가?  

DWH와 같은 분석형 쿼리는 기존 데이터베이스와 잘 맞지 않는 경향이 있다. 그래서 나온 것이 Column-Oriented Database 이다. 기존의 데이터베이스가 행(레코드)를 단위로 데이터를 처리한다면, 열(컬럼)을 단위로 데이터를 처리한다는 차이가 있다.  
기존의 RDBMS는 인덱스를 활용하는 것을 전제로 만들어져 있다. 인덱스를 사용해서 레코드 단위 기반 액세스를 최적화하고, 참조도 갱신도 균형있게 처리한다. 인덱스 검색은 랜덤 read 라는 특성 상, 한 개의 레코드만 일치하는 유형의 검색이 가장 높은 성능을 낼 수 있다.  

### 열 지향 데이터베이스의 장점  

#### 필요한 열만 액세스되기 때문에 I/O 효율이 높다  

열 지향 데이터베이스에서는 필요한 열만 액세스하는 성질이 있다. 그래서 기존 레코드 기반 DB에 비해서 필요한 I/O 양이 줄어든다. 개별 쿼리에 필요한 열이 적은 분석형 쿼리의 경우 I/O 전송량을 줄여서 전체 처리량을 높일 수 있다.  

#### 압축 효율이 좋다  

일단적으로 DWH에서 카디널리티가 작아지는 경향이 있다. 또한 값의 편차에도 일정한 경향을 보이는 경우가 많다. 비슷한 값들이 많다는 이야기는 압축 효율이 높다는 이야기이다. 그러면 데이터 크기를 크게 줄일 수 있고, 데이터 크기가 줄어들면 디스크 I/O 발생 빈도도 줄어들어 성능 향상을 얻을 수 있다.  

#### 로드 처리가 고속이다  

열 지향 데이터베이스는 B+Tree를 사용하지 않는 제품이 있다. 그러면 데이터가 늘어나더라도 일정 이상의 업데이트 성능을 유지할 수 있다. 또한 열 지향 데이터베이스에서는 먼저 필요한 컬럼만 로드하기 때문에 로드가 빠르다.  
B+Tree 인덱스에서는 열 값을 정렬이 끝난 상태로 유지할 필요가 있다. 그래서 데이터가 계속해서 들어오면 정렬에 비용이 발생한다. 기본적으로 이 정렬 비용은 `O(logN)` 이며, 레코드 수가 많을수록 처리 비용이 증가한다. 또한 인덱스를 업데이트하기 위해서는 그 업데이트 대상이 메모리에 로드되어 있지 않으면 안된다. 로드 처리에 의해 이곳저곳 블록을 갱신하는 경우에는 많은 블록에 대해 랜덤 read가 발생하기 때문에 처리 성능이 떨어질 수 있다.  

### 열 지향 데이터베이스의 단점  

#### 기본 키 검색 등 좁은 범위의 처리가 느리다  

B+Tree의 색인과 같은 고유 검색과 매우 좁은 범위의 검색에 최적화된 인덱스를 사용할 수 없는 경우가 많다. 인덱스를 가질 수 없기 때문에 고유성을 보장 못하는 제품도 있다. 제품에 따라서 한 개 레코드를 기본 키 검색하는 것만으로도 큰 범위의 검색이 필요할 수 있다.  

#### 제품으로서의 성숙도가 낮다  

책에서는 아직 성숙한 제품이 많이 없다고 하는데 이제 유명한 제품이 많이 있다. MariaDB, ClickHouse, Apache HBase, Apache Kudu, Apache Parquet 등..  
